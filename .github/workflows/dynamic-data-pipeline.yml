name: Dynamic Asset Data Pipeline

on:
  schedule:
    # Run daily at 6 AM UTC
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      tickers:
        description: 'Comma-separated list of tickers to process'
        required: false
        default: ''

jobs:
  dynamic-data-pipeline:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        cd services/data-pipeline
        pip install -r requirements.txt
        
    - name: Run dynamic asset fetcher
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      run: |
        cd services/data-pipeline
        python dynamic_asset_fetcher.py
        
    - name: Process specific tickers (if provided)
      if: ${{ github.event.inputs.tickers != '' }}
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      run: |
        cd services/data-pipeline
        IFS=',' read -ra TICKERS <<< "${{ github.event.inputs.tickers }}"
        for ticker in "${TICKERS[@]}"; do
          echo "Processing ticker: $ticker"
          python add_new_asset.py "$ticker"
        done
        
    - name: Generate summary report
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      run: |
        cd services/data-pipeline
        python -c "
        import os
        from supabase import create_client
        
        client = create_client(os.getenv('SUPABASE_URL'), os.getenv('SUPABASE_KEY'))
        
        # Get asset count
        result = client.table('asset_returns').select('asset_ticker', count='exact').execute()
        asset_count = result.count
        
        # Get unique assets
        assets_result = client.table('asset_returns').select('asset_ticker').execute()
        unique_assets = len(set(row['asset_ticker'] for row in assets_result.data))
        
        print(f'Total data points: {asset_count}')
        print(f'Unique assets: {unique_assets}')
        "
        
    - name: Upload logs
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: pipeline-logs-${{ github.run_number }}
        path: |
          services/data-pipeline/*.log
          services/data-pipeline/*.txt
